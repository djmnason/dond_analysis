{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "951fd1ae-0628-4347-bd5a-ecf8a3ad0284",
   "metadata": {},
   "source": [
    "# setup for data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f2fe7-26f1-4aca-8aac-7d0753255d57",
   "metadata": {},
   "source": [
    "### web scraping metadata from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "319e4e09-5278-4096-9dc0-928fec7849d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, TimeoutException\n",
    "from datetime import datetime\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ed3ea-4973-4e86-bfd7-df94b877588d",
   "metadata": {},
   "source": [
    "#### constants for web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bafb6e3-5879-4300-bbf2-a3b2ccd21f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## where data are located\n",
    "url = 'https://www.imdb.com/title/tt0493378/episodes/?season=1'\n",
    "num_seasons = 5\n",
    "## css location of buttons on page to select in imdb\n",
    "dropdown_selector = '#__next > main > div > section > div > section > div > div.sc-a83bf66d-1.gYStnb.ipc-page-grid__item.ipc-page-grid__item--span-2 > section:nth-child(2) > section.sc-46954f9-0.hOJNkT > article:nth-child(51) > div > span.ipc-see-more.sc-b79d292e-0.eAzFWZ.single-page-see-more-button > button'\n",
    "next_page_selector = '#next-season-btn'\n",
    "episodes_selector = '#__next > main > div > section > div > section > div > div.sc-a83bf66d-1.gYStnb.ipc-page-grid__item.ipc-page-grid__item--span-2 > section:nth-child(2) > section.sc-46954f9-0.hOJNkT > article'\n",
    "episode_title_selector = 'div > div > div.sc-9115db22-4.kyIRYf > div.sc-9115db22-5.ewoZOO > h4 > div > a > div'\n",
    "episode_date_selector = 'div > div > div.sc-9115db22-4.kyIRYf > div.sc-9115db22-5.ewoZOO > span'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7ba65-1398-4113-96aa-9cd494710c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## original attempt at data collection\n",
    "# soups = []\n",
    "# base_url = 'https://www.imdb.com/title/tt0493378/episodes/?season='\n",
    "# headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "# num_seasons=5\n",
    "# for i in range(1, num_seasons+1):\n",
    "#     curr_response = requests.get(f'{base_url}{i}', headers=headers)\n",
    "#     if curr_response.status_code == 200:\n",
    "#         soups.append(BeautifulSoup(curr_response.text, 'html.parser'))\n",
    "#         print(f'Response for season {i} was successful')\n",
    "#         time.sleep(np.random.randint(5, 10))\n",
    "#     else:\n",
    "#         print(f\"Failed to retrieve the page. Status code: {curr_response.status_code}\")\n",
    "# print(len(responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7bcb0-19f2-4ca3-a350-6ba6626a1479",
   "metadata": {},
   "source": [
    "#### helper functions to collect data and tidy it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0109a07a-454b-44c4-a276-f8cecce7fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_click_attempts(driver, click_type:str=None, css_path:str=None, i:int=None):\n",
    "    stop_bool = False\n",
    "    j = 1\n",
    "    while not stop_bool:\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_path))).click()\n",
    "            stop_bool = True\n",
    "            print(f'successfully clicked {click_type} for season {i+1} with try {j}')\n",
    "        except ElementClickInterceptedException:\n",
    "            print(f'failed {click_type} for season {i+1} on try {j}')\n",
    "            j += 1\n",
    "            continue\n",
    "        except TimeoutException:\n",
    "            print(f'season {i+1} does not have {click_type}')\n",
    "            stop_bool = True\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f13db3-2b26-4da4-ad6e-5fcf53836ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_set_to_string(result_set):\n",
    "    return result_set[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4118e168-b1db-4530-992e-1c6c0b8ac085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_episode_title(title_string:str) -> dict:\n",
    "    title_string = result_set_to_string(title_string)\n",
    "    season_episode, title = [c.strip() for c in title_string.split('âˆ™')]\n",
    "    season, episode = [''.join(re.findall(r'\\d', c)) for c in season_episode.split('.')]\n",
    "    return {'season' : season, 'episode' : episode, 'title' : title}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1be31f64-95f0-49dc-86be-e581453beffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_episode_date(date_string:str, date_format:str='%a, %b %d, %Y') -> dict:\n",
    "    date_string = result_set_to_string(date_string)\n",
    "    return {'air_date' : datetime.strptime(date_string, date_format)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b5f8083-fa1d-4189-9fb1-1c24abc11a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_episode_metadata(title_string:str, date_string:str) -> dict:\n",
    "    return {**extract_episode_title(title_string), **extract_episode_date(date_string)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8cd38e8-3239-43bb-a0f7-14e08c3e811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imdb_episode_data():\n",
    "    soups = []\n",
    "    driver = webdriver.Chrome()\n",
    "    print('launching url')\n",
    "    driver.get(url)\n",
    "    print('attempting to scrape web page')\n",
    "    for i in range(num_seasons):\n",
    "        ## activating dropdown\n",
    "        repeated_click_attempts(driver=driver, click_type='dropdown', css_path=dropdown_selector, i=i)\n",
    "        print()\n",
    "        ## scrape the page and store results\n",
    "        print(f'appending soup for season {i+1}')\n",
    "        time.sleep(5)\n",
    "        soups.append(BeautifulSoup(driver.page_source, 'html.parser').select(episodes_selector))\n",
    "        print()    \n",
    "        repeated_click_attempts(driver=driver, click_type='next page', css_path=next_page_selector, i=i)\n",
    "    print('done')\n",
    "    driver.quit()\n",
    "    return soups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b1590-b4c3-4dd0-b806-b8d3818c061d",
   "metadata": {},
   "source": [
    "### organizing and tidying the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16099b-a593-49dc-8f94-9638feb76372",
   "metadata": {},
   "source": [
    "#### webscraping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0bcfb38-77da-4f65-a010-e76c0ba06c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error sending stats to Plausible: error sending request for url (https://plausible.io/api/event)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "launching url\n",
      "attempting to scrape web page\n",
      "season 1 does not have dropdown\n",
      "\n",
      "appending soup for season 1\n",
      "\n",
      "failed next page for season 1 on try 1\n",
      "successfully clicked next page for season 1 with try 2\n",
      "season 2 does not have dropdown\n",
      "\n",
      "appending soup for season 2\n",
      "\n",
      "failed next page for season 2 on try 1\n",
      "successfully clicked next page for season 2 with try 2\n",
      "season 3 does not have dropdown\n",
      "\n",
      "appending soup for season 3\n",
      "\n",
      "failed next page for season 3 on try 1\n",
      "successfully clicked next page for season 3 with try 2\n",
      "season 4 does not have dropdown\n",
      "\n",
      "appending soup for season 4\n",
      "\n",
      "failed next page for season 4 on try 1\n",
      "successfully clicked next page for season 4 with try 2\n",
      "season 5 does not have dropdown\n",
      "\n",
      "appending soup for season 5\n",
      "\n",
      "failed next page for season 5 on try 1\n",
      "successfully clicked next page for season 5 with try 2\n",
      "done\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "## getting the raw data\n",
    "soups = get_imdb_episode_data()\n",
    "## organizing the raw data\n",
    "episode_metadata = pd.DataFrame([\n",
    "    extract_episode_metadata(episode.select(episode_title_selector), episode.select(episode_date_selector)) ## extract the metadata\n",
    "    for episodes in soups ## for all seasons\n",
    "    for episode in episodes ## for all episodes in each season\n",
    "])\n",
    "## viewing the data\n",
    "print(episode_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd838fb4-1c9f-4eee-bf35-803575fcc255",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting up the data collection board\n",
    "rounds = [1,1,1,1,1,1,2,2,2,2,2,3,3,3,3,4,4,4,5,5,6,7,8,9,10,11]\n",
    "round_turns = [1,2,3,4,5,6,1,2,3,4,5,1,2,3,4,1,2,3,1,2,1,1,1,1,1,1]\n",
    "base_board = pd.DataFrame({'round' : rounds, 'round_turn' : round_turns}).assign(\n",
    "    case = '',\n",
    "    value = '',\n",
    "    offer = '',\n",
    "    game_ended = '',\n",
    "    original_case = '',\n",
    "    winnings = '',\n",
    ")\n",
    "base_board.loc[base_board['round'] == 10, 'game_ended'] = '1'\n",
    "base_board.loc[(base_board['round'] == 10) & (base_board['round_turn'] == 1), 'original_case'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83903924-6413-457e-8070-64fa0b601181",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_games = episode_metadata.shape[0]\n",
    "final_board = pd.concat([base_board.copy() for _ in range(total_games)])\n",
    "final_board.insert(0, 'ID', np.repeat(range(1, total_games + 1), base_board.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881f7b4-94e5-4ac6-b878-cbd4538a6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_board.to_csv('data_entry_template.csv', index=False)\n",
    "episode_metadata.to_csv('dond_episode_metadata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
